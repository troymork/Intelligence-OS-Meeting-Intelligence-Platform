"""
Oracle Intelligence System - InsightSynthesizer
Transforms individual debrief insights into collective organizational intelligence

This module analyzes patterns across all team debriefs to:
- Identify psychological trends and team evolution patterns
- Generate strategic insights from collective intelligence
- Build knowledge graphs of organizational wisdom
- Predict decision impacts and team dynamics
- Create project-specific intelligence for Impact Launchpad initiatives
- Synthesize insights into actionable organizational learning
"""

import os
import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, Counter
import uuid

from Mem0Manager import Mem0Manager, DebriefEntry, TeamMember
from EnhancedTankaProfileLoader import EnhancedTankaProfileLoader, PsychologicalProfile, MBTIType, DISCType
from DebriefCollector import DebriefCollector, DebriefResult, CollectiveDebriefSummary

class InsightType(Enum):
    """Types of insights generated by the synthesizer"""
    STRATEGIC = "strategic"
    OPERATIONAL = "operational"
    PSYCHOLOGICAL = "psychological"
    PROJECT_SPECIFIC = "project_specific"
    TEAM_DYNAMICS = "team_dynamics"
    DECISION_IMPACT = "decision_impact"
    TREND_PREDICTION = "trend_prediction"
    KNOWLEDGE_SYNTHESIS = "knowledge_synthesis"

class InsightPriority(Enum):
    """Priority levels for insights"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFORMATIONAL = "informational"

class TrendDirection(Enum):
    """Direction of identified trends"""
    IMPROVING = "improving"
    DECLINING = "declining"
    STABLE = "stable"
    VOLATILE = "volatile"
    EMERGING = "emerging"

@dataclass
class SynthesizedInsight:
    """A synthesized insight from collective intelligence analysis"""
    insight_id: str
    insight_type: InsightType
    priority: InsightPriority
    title: str
    description: str
    supporting_evidence: List[str]
    affected_projects: List[str]
    affected_team_members: List[str]
    psychological_factors: Dict[str, Any]
    confidence_score: float
    actionable_recommendations: List[str]
    predicted_impact: Dict[str, Any]
    related_insights: List[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    expires_at: Optional[datetime] = None

@dataclass
class TeamTrend:
    """Identified trend in team behavior or performance"""
    trend_id: str
    trend_type: str
    direction: TrendDirection
    strength: float  # 0.0 to 1.0
    description: str
    time_period: str
    affected_members: List[str]
    psychological_indicators: Dict[str, Any]
    supporting_data: List[Dict[str, Any]]
    predicted_trajectory: Dict[str, Any]
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class KnowledgeNode:
    """Node in the organizational knowledge graph"""
    node_id: str
    node_type: str  # concept, decision, insight, pattern, project
    title: str
    description: str
    attributes: Dict[str, Any]
    connections: List[str] = field(default_factory=list)
    strength_scores: Dict[str, float] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)

@dataclass
class ProjectIntelligence:
    """Project-specific intelligence summary"""
    project_name: str
    project_producer: str
    key_insights: List[SynthesizedInsight]
    team_engagement: Dict[str, float]
    psychological_alignment: Dict[str, Any]
    success_indicators: List[str]
    risk_factors: List[str]
    optimization_opportunities: List[str]
    predicted_outcomes: Dict[str, Any]
    last_updated: datetime = field(default_factory=datetime.now)

class InsightSynthesizer:
    """
    Transforms individual debrief insights into collective organizational intelligence
    
    Analyzes patterns across all team debriefs to generate strategic insights,
    build knowledge graphs, predict trends, and create project-specific intelligence
    for the Impact Launchpad ecosystem.
    """
    
    def __init__(self, mem0_manager: Mem0Manager, enhanced_tanka: EnhancedTankaProfileLoader, debrief_collector: DebriefCollector):
        """Initialize InsightSynthesizer with integrated components"""
        self.mem0_manager = mem0_manager
        self.enhanced_tanka = enhanced_tanka
        self.debrief_collector = debrief_collector
        
        # Insight storage
        self.synthesized_insights: Dict[str, SynthesizedInsight] = {}
        self.team_trends: Dict[str, TeamTrend] = {}
        self.knowledge_graph: Dict[str, KnowledgeNode] = {}
        self.project_intelligence: Dict[str, ProjectIntelligence] = {}
        
        # Impact Launchpad project definitions
        self.impact_projects = {
            "100_percent_project": {
                "name": "100% Project",
                "producer": "daniel",
                "sub_projects": [
                    "#isThereEnough?", "The Agreement Economy", "Human Rights Wallet",
                    "Fuller Treaty of Humanity", "Bank of Humanity", "The First Agreement Book",
                    "Commitment Tech", "HumaniT", "#IsThereEnoughTV", "Universal Income Project"
                ],
                "focus_areas": ["human_rights", "economic_systems", "social_impact", "technology"]
            },
            "spark": {
                "name": "SPARK",
                "producer": "troy",
                "sub_projects": [],
                "focus_areas": ["innovation", "systematic_approach", "project_management", "efficiency"]
            },
            "ecoco": {
                "name": "Ecoco",
                "producer": "marc",
                "sub_projects": [],
                "focus_areas": ["sustainability", "environmental_impact", "green_technology", "climate_action"]
            },
            "treegens": {
                "name": "TreeGens",
                "producer": "jimi",
                "sub_projects": [],
                "focus_areas": ["regenerative_systems", "nature_based_solutions", "ecosystem_restoration", "biodiversity"]
            }
        }
        
        # Analysis configuration
        self.min_data_points = 3
        self.trend_analysis_window_days = 30
        self.insight_confidence_threshold = 0.6
        self.knowledge_connection_threshold = 0.5
        
        print("üß† InsightSynthesizer initialized with collective intelligence capabilities")
    
    def analyze_collective_patterns(self, time_window_days: int = 30) -> Dict[str, Any]:
        """Analyze patterns across all team debriefs within time window"""
        print(f"üîç Analyzing collective patterns over {time_window_days} days...")
        
        # Get recent debrief data
        cutoff_date = datetime.now() - timedelta(days=time_window_days)
        recent_debriefs = self._get_recent_debriefs(cutoff_date)
        
        if len(recent_debriefs) < self.min_data_points:
            print(f"‚ö†Ô∏è Insufficient data points ({len(recent_debriefs)}) for pattern analysis")
            return {"status": "insufficient_data", "data_points": len(recent_debriefs)}
        
        patterns = {
            "psychological_patterns": self._analyze_psychological_patterns(recent_debriefs),
            "communication_patterns": self._analyze_communication_patterns(recent_debriefs),
            "decision_patterns": self._analyze_decision_patterns(recent_debriefs),
            "stress_engagement_patterns": self._analyze_stress_engagement_patterns(recent_debriefs),
            "project_alignment_patterns": self._analyze_project_alignment_patterns(recent_debriefs),
            "team_evolution_patterns": self._analyze_team_evolution_patterns(recent_debriefs)
        }
        
        print(f"‚úÖ Collective pattern analysis complete: {len(patterns)} pattern categories identified")
        return patterns
    
    def _get_recent_debriefs(self, cutoff_date: datetime) -> List[DebriefResult]:
        """Get recent debrief results for analysis"""
        recent_debriefs = []
        
        # Get debriefs from debrief_collector
        for result in self.debrief_collector.debrief_results.values():
            if result.completion_time and result.completion_time >= cutoff_date:
                recent_debriefs.append(result)
        
        # Also get debriefs from Mem0 (would require additional implementation)
        # For now, using debrief_collector results
        
        return recent_debriefs
    
    def _analyze_psychological_patterns(self, debriefs: List[DebriefResult]) -> Dict[str, Any]:
        """Analyze psychological patterns across debriefs"""
        patterns = {
            "mbti_distribution_trends": {},
            "disc_communication_evolution": {},
            "big_five_trait_changes": {},
            "stress_response_patterns": {},
            "engagement_optimization_insights": {}
        }
        
        # MBTI distribution analysis
        mbti_counts = Counter()
        mbti_stress_levels = defaultdict(list)
        mbti_engagement_levels = defaultdict(list)
        
        for debrief in debriefs:
            if "mbti_alignment" in debrief.psychological_insights:
                mbti_type = debrief.psychological_insights["mbti_alignment"]["type"]
                mbti_counts[mbti_type] += 1
                mbti_stress_levels[mbti_type].append(debrief.stress_level)
                mbti_engagement_levels[mbti_type].append(debrief.engagement_level)
        
        # Calculate MBTI patterns
        for mbti_type, count in mbti_counts.items():
            avg_stress = np.mean(mbti_stress_levels[mbti_type]) if mbti_stress_levels[mbti_type] else 0
            avg_engagement = np.mean(mbti_engagement_levels[mbti_type]) if mbti_engagement_levels[mbti_type] else 0
            
            patterns["mbti_distribution_trends"][mbti_type] = {
                "frequency": count,
                "average_stress": avg_stress,
                "average_engagement": avg_engagement,
                "stress_variance": np.var(mbti_stress_levels[mbti_type]) if len(mbti_stress_levels[mbti_type]) > 1 else 0
            }
        
        # DISC communication evolution
        disc_patterns = defaultdict(lambda: {"count": 0, "stress_levels": [], "engagement_levels": []})
        
        for debrief in debriefs:
            if "disc_communication_style" in debrief.psychological_insights:
                disc_type = debrief.psychological_insights["disc_communication_style"]["type"]
                disc_patterns[disc_type]["count"] += 1
                disc_patterns[disc_type]["stress_levels"].append(debrief.stress_level)
                disc_patterns[disc_type]["engagement_levels"].append(debrief.engagement_level)
        
        for disc_type, data in disc_patterns.items():
            patterns["disc_communication_evolution"][disc_type] = {
                "frequency": data["count"],
                "average_stress": np.mean(data["stress_levels"]) if data["stress_levels"] else 0,
                "average_engagement": np.mean(data["engagement_levels"]) if data["engagement_levels"] else 0
            }
        
        return patterns
    
    def _analyze_communication_patterns(self, debriefs: List[DebriefResult]) -> Dict[str, Any]:
        """Analyze communication patterns across team"""
        patterns = {
            "response_quality_trends": {},
            "communication_style_effectiveness": {},
            "collaboration_indicators": {},
            "information_sharing_patterns": {}
        }
        
        # Response quality analysis
        quality_by_member = defaultdict(list)
        quality_by_mbti = defaultdict(list)
        
        for debrief in debriefs:
            quality_score = self._quality_to_score(debrief.response_quality)
            quality_by_member[debrief.user_id].append(quality_score)
            
            if "mbti_alignment" in debrief.psychological_insights:
                mbti_type = debrief.psychological_insights["mbti_alignment"]["type"]
                quality_by_mbti[mbti_type].append(quality_score)
        
        # Calculate quality trends
        for member_id, scores in quality_by_member.items():
            member = self.mem0_manager.team_members.get(member_id)
            if member:
                patterns["response_quality_trends"][member.name] = {
                    "average_quality": np.mean(scores),
                    "quality_variance": np.var(scores) if len(scores) > 1 else 0,
                    "trend": "improving" if len(scores) > 1 and scores[-1] > scores[0] else "stable"
                }
        
        # MBTI communication effectiveness
        for mbti_type, scores in quality_by_mbti.items():
            patterns["communication_style_effectiveness"][mbti_type] = {
                "average_quality": np.mean(scores),
                "sample_size": len(scores)
            }
        
        return patterns
    
    def _quality_to_score(self, quality) -> float:
        """Convert response quality enum to numeric score"""
        quality_scores = {
            "excellent": 1.0,
            "good": 0.8,
            "adequate": 0.6,
            "poor": 0.4,
            "incomplete": 0.2
        }
        return quality_scores.get(quality.value if hasattr(quality, 'value') else str(quality), 0.5)
    
    def _analyze_decision_patterns(self, debriefs: List[DebriefResult]) -> Dict[str, Any]:
        """Analyze decision-making patterns across team"""
        patterns = {
            "decision_making_styles": {},
            "consensus_patterns": {},
            "decision_confidence_trends": {},
            "implementation_concerns": {}
        }
        
        # Decision-making style analysis
        decision_styles = defaultdict(list)
        
        for debrief in debriefs:
            if "decision_making_style" in debrief.psychological_insights:
                style_data = debrief.psychological_insights["decision_making_style"]
                style = style_data.get("primary_style", "balanced")
                confidence = style_data.get("confidence_level", 0.5)
                
                decision_styles[style].append({
                    "confidence": confidence,
                    "user_id": debrief.user_id,
                    "stress_level": debrief.stress_level
                })
        
        # Calculate decision style patterns
        for style, data_points in decision_styles.items():
            avg_confidence = np.mean([dp["confidence"] for dp in data_points])
            avg_stress = np.mean([dp["stress_level"] for dp in data_points])
            
            patterns["decision_making_styles"][style] = {
                "frequency": len(data_points),
                "average_confidence": avg_confidence,
                "average_stress_during_decisions": avg_stress,
                "effectiveness_indicator": avg_confidence * (1 - avg_stress)  # High confidence, low stress = effective
            }
        
        return patterns
    
    def _analyze_stress_engagement_patterns(self, debriefs: List[DebriefResult]) -> Dict[str, Any]:
        """Analyze stress and engagement patterns"""
        patterns = {
            "stress_trends": {},
            "engagement_trends": {},
            "stress_engagement_correlation": {},
            "psychological_wellbeing_indicators": {}
        }
        
        # Collect stress and engagement data
        member_stress = defaultdict(list)
        member_engagement = defaultdict(list)
        overall_stress = []
        overall_engagement = []
        
        for debrief in debriefs:
            member_stress[debrief.user_id].append(debrief.stress_level)
            member_engagement[debrief.user_id].append(debrief.engagement_level)
            overall_stress.append(debrief.stress_level)
            overall_engagement.append(debrief.engagement_level)
        
        # Calculate individual trends
        for member_id, stress_levels in member_stress.items():
            engagement_levels = member_engagement[member_id]
            member = self.mem0_manager.team_members.get(member_id)
            
            if member and len(stress_levels) > 1:
                stress_trend = "improving" if stress_levels[-1] < stress_levels[0] else "declining" if stress_levels[-1] > stress_levels[0] else "stable"
                engagement_trend = "improving" if engagement_levels[-1] > engagement_levels[0] else "declining" if engagement_levels[-1] < engagement_levels[0] else "stable"
                
                patterns["stress_trends"][member.name] = {
                    "current_level": stress_levels[-1],
                    "average_level": np.mean(stress_levels),
                    "trend": stress_trend,
                    "variance": np.var(stress_levels)
                }
                
                patterns["engagement_trends"][member.name] = {
                    "current_level": engagement_levels[-1],
                    "average_level": np.mean(engagement_levels),
                    "trend": engagement_trend,
                    "variance": np.var(engagement_levels)
                }
        
        # Overall correlation
        if len(overall_stress) > 2:
            correlation = np.corrcoef(overall_stress, overall_engagement)[0, 1]
            patterns["stress_engagement_correlation"] = {
                "correlation_coefficient": correlation,
                "interpretation": "negative" if correlation < -0.3 else "positive" if correlation > 0.3 else "neutral"
            }
        
        return patterns
    
    def _analyze_project_alignment_patterns(self, debriefs: List[DebriefResult]) -> Dict[str, Any]:
        """Analyze alignment patterns with Impact Launchpad projects"""
        patterns = {
            "project_engagement": {},
            "cross_project_insights": {},
            "producer_leadership_patterns": {},
            "project_psychological_fit": {}
        }
        
        # Analyze project-related content in responses
        project_keywords = {
            "100_percent_project": ["human rights", "agreement", "economy", "humanity", "universal", "commitment"],
            "spark": ["innovation", "systematic", "efficiency", "project management", "optimization"],
            "ecoco": ["sustainability", "environmental", "green", "climate", "eco", "carbon"],
            "treegens": ["regenerative", "nature", "ecosystem", "biodiversity", "restoration", "trees"]
        }
        
        project_mentions = defaultdict(lambda: defaultdict(int))
        project_engagement_scores = defaultdict(lambda: defaultdict(list))
        
        for debrief in debriefs:
            # Analyze response content for project keywords
            all_responses = " ".join(debrief.responses.values()).lower()
            
            for project_id, keywords in project_keywords.items():
                mention_count = sum(1 for keyword in keywords if keyword in all_responses)
                if mention_count > 0:
                    project_mentions[project_id][debrief.user_id] += mention_count
                    project_engagement_scores[project_id][debrief.user_id].append(debrief.engagement_level)
        
        # Calculate project engagement patterns
        for project_id, member_mentions in project_mentions.items():
            project_data = self.impact_projects.get(project_id, {})
            producer_id = project_data.get("producer")
            
            patterns["project_engagement"][project_id] = {
                "total_mentions": sum(member_mentions.values()),
                "engaged_members": list(member_mentions.keys()),
                "producer_engagement": member_mentions.get(producer_id, 0),
                "cross_team_interest": len(member_mentions) - (1 if producer_id in member_mentions else 0)
            }
            
            # Calculate average engagement for this project
            if project_id in project_engagement_scores:
                all_engagement = []
                for member_scores in project_engagement_scores[project_id].values():
                    all_engagement.extend(member_scores)
                
                if all_engagement:
                    patterns["project_engagement"][project_id]["average_engagement"] = np.mean(all_engagement)
        
        return patterns
    
    def _analyze_team_evolution_patterns(self, debriefs: List[DebriefResult]) -> Dict[str, Any]:
        """Analyze how the team is evolving over time"""
        patterns = {
            "collaboration_evolution": {},
            "psychological_maturity": {},
            "communication_improvement": {},
            "collective_intelligence_growth": {}
        }
        
        # Sort debriefs by completion time
        sorted_debriefs = sorted([d for d in debriefs if d.completion_time], 
                               key=lambda x: x.completion_time)
        
        if len(sorted_debriefs) < 3:
            return patterns
        
        # Analyze evolution in thirds (early, middle, recent)
        third_size = len(sorted_debriefs) // 3
        early_debriefs = sorted_debriefs[:third_size]
        middle_debriefs = sorted_debriefs[third_size:2*third_size]
        recent_debriefs = sorted_debriefs[2*third_size:]
        
        periods = {
            "early": early_debriefs,
            "middle": middle_debriefs,
            "recent": recent_debriefs
        }
        
        # Calculate metrics for each period
        period_metrics = {}
        for period_name, period_debriefs in periods.items():
            if period_debriefs:
                avg_stress = np.mean([d.stress_level for d in period_debriefs])
                avg_engagement = np.mean([d.engagement_level for d in period_debriefs])
                avg_quality = np.mean([self._quality_to_score(d.response_quality) for d in period_debriefs])
                
                period_metrics[period_name] = {
                    "average_stress": avg_stress,
                    "average_engagement": avg_engagement,
                    "average_quality": avg_quality,
                    "sample_size": len(period_debriefs)
                }
        
        # Calculate evolution trends
        if len(period_metrics) >= 2:
            early_metrics = period_metrics.get("early", {})
            recent_metrics = period_metrics.get("recent", {})
            
            if early_metrics and recent_metrics:
                patterns["collaboration_evolution"] = {
                    "stress_change": recent_metrics["average_stress"] - early_metrics["average_stress"],
                    "engagement_change": recent_metrics["average_engagement"] - early_metrics["average_engagement"],
                    "quality_change": recent_metrics["average_quality"] - early_metrics["average_quality"],
                    "overall_trend": "improving" if (
                        recent_metrics["average_engagement"] > early_metrics["average_engagement"] and
                        recent_metrics["average_stress"] < early_metrics["average_stress"]
                    ) else "stable"
                }
        
        return patterns
    
    def generate_strategic_insights(self, patterns: Dict[str, Any]) -> List[SynthesizedInsight]:
        """Generate strategic insights from collective patterns"""
        print("üéØ Generating strategic insights from collective patterns...")
        
        insights = []
        
        # Generate psychological insights
        insights.extend(self._generate_psychological_insights(patterns))
        
        # Generate team dynamics insights
        insights.extend(self._generate_team_dynamics_insights(patterns))
        
        # Generate project-specific insights
        insights.extend(self._generate_project_insights(patterns))
        
        # Generate decision-making insights
        insights.extend(self._generate_decision_insights(patterns))
        
        # Generate trend prediction insights
        insights.extend(self._generate_trend_insights(patterns))
        
        # Store insights
        for insight in insights:
            self.synthesized_insights[insight.insight_id] = insight
        
        print(f"‚úÖ Generated {len(insights)} strategic insights")
        return insights
    
    def _generate_psychological_insights(self, patterns: Dict[str, Any]) -> List[SynthesizedInsight]:
        """Generate insights about team psychological patterns"""
        insights = []
        
        psych_patterns = patterns.get("psychological_patterns", {})
        mbti_trends = psych_patterns.get("mbti_distribution_trends", {})
        
        # MBTI stress pattern insight
        if mbti_trends:
            high_stress_types = [mbti for mbti, data in mbti_trends.items() 
                               if data.get("average_stress", 0) > 0.6]
            
            if high_stress_types:
                insight = SynthesizedInsight(
                    insight_id=str(uuid.uuid4()),
                    insight_type=InsightType.PSYCHOLOGICAL,
                    priority=InsightPriority.HIGH,
                    title="High Stress Patterns in Specific MBTI Types",
                    description=f"Team members with {', '.join(high_stress_types)} personality types are showing elevated stress levels in recent debriefs.",
                    supporting_evidence=[
                        f"{mbti}: {mbti_trends[mbti]['average_stress']:.1f} average stress" 
                        for mbti in high_stress_types
                    ],
                    affected_projects=list(self.impact_projects.keys()),
                    affected_team_members=[],  # Would need mapping from MBTI to team members
                    psychological_factors={
                        "mbti_stress_correlation": {mbti: mbti_trends[mbti] for mbti in high_stress_types},
                        "stress_threshold": 0.6
                    },
                    confidence_score=0.8,
                    actionable_recommendations=[
                        f"Provide additional support for {', '.join(high_stress_types)} personality types",
                        "Consider workload redistribution or stress management resources",
                        "Implement MBTI-specific stress reduction strategies"
                    ],
                    predicted_impact={
                        "team_wellbeing": "positive",
                        "productivity": "improved",
                        "retention": "higher"
                    }
                )
                insights.append(insight)
        
        return insights
    
    def _generate_team_dynamics_insights(self, patterns: Dict[str, Any]) -> List[SynthesizedInsight]:
        """Generate insights about team dynamics and collaboration"""
        insights = []
        
        stress_patterns = patterns.get("stress_engagement_patterns", {})
        correlation_data = stress_patterns.get("stress_engagement_correlation", {})
        
        # Stress-engagement correlation insight
        if correlation_data:
            correlation = correlation_data.get("correlation_coefficient", 0)
            
            if abs(correlation) > 0.5:  # Strong correlation
                insight = SynthesizedInsight(
                    insight_id=str(uuid.uuid4()),
                    insight_type=InsightType.TEAM_DYNAMICS,
                    priority=InsightPriority.MEDIUM,
                    title=f"{'Strong Negative' if correlation < 0 else 'Strong Positive'} Stress-Engagement Correlation",
                    description=f"Team shows a {correlation_data.get('interpretation', 'significant')} correlation ({correlation:.2f}) between stress and engagement levels.",
                    supporting_evidence=[
                        f"Correlation coefficient: {correlation:.2f}",
                        f"Pattern interpretation: {correlation_data.get('interpretation', 'significant')}"
                    ],
                    affected_projects=list(self.impact_projects.keys()),
                    affected_team_members=[],
                    psychological_factors={
                        "correlation_strength": abs(correlation),
                        "correlation_direction": "negative" if correlation < 0 else "positive"
                    },
                    confidence_score=min(abs(correlation), 0.9),
                    actionable_recommendations=[
                        "Monitor stress levels as leading indicator of engagement" if correlation < 0 else "Investigate why high stress correlates with high engagement",
                        "Implement stress management strategies to optimize engagement",
                        "Consider team workload and meeting frequency adjustments"
                    ],
                    predicted_impact={
                        "team_performance": "improved",
                        "meeting_effectiveness": "higher",
                        "team_satisfaction": "increased"
                    }
                )
                insights.append(insight)
        
        return insights
    
    def _generate_project_insights(self, patterns: Dict[str, Any]) -> List[SynthesizedInsight]:
        """Generate project-specific insights for Impact Launchpad initiatives"""
        insights = []
        
        project_patterns = patterns.get("project_alignment_patterns", {})
        project_engagement = project_patterns.get("project_engagement", {})
        
        for project_id, engagement_data in project_engagement.items():
            project_info = self.impact_projects.get(project_id, {})
            project_name = project_info.get("name", project_id)
            
            cross_team_interest = engagement_data.get("cross_team_interest", 0)
            total_mentions = engagement_data.get("total_mentions", 0)
            
            if cross_team_interest > 2:  # Significant cross-team interest
                insight = SynthesizedInsight(
                    insight_id=str(uuid.uuid4()),
                    insight_type=InsightType.PROJECT_SPECIFIC,
                    priority=InsightPriority.HIGH,
                    title=f"High Cross-Team Interest in {project_name}",
                    description=f"{project_name} is generating significant interest across {cross_team_interest} team members beyond the producer.",
                    supporting_evidence=[
                        f"Total project mentions: {total_mentions}",
                        f"Cross-team engagement: {cross_team_interest} members",
                        f"Engaged members: {', '.join(engagement_data.get('engaged_members', []))}"
                    ],
                    affected_projects=[project_id],
                    affected_team_members=engagement_data.get("engaged_members", []),
                    psychological_factors={
                        "cross_team_appeal": cross_team_interest,
                        "engagement_breadth": len(engagement_data.get("engaged_members", []))
                    },
                    confidence_score=min(cross_team_interest / 5.0, 0.9),
                    actionable_recommendations=[
                        f"Consider expanding {project_name} team to include interested members",
                        "Leverage cross-team interest for collaborative opportunities",
                        "Document and share insights that are generating broad appeal"
                    ],
                    predicted_impact={
                        "project_success": "higher",
                        "team_collaboration": "increased",
                        "innovation_potential": "enhanced"
                    }
                )
                insights.append(insight)
        
        return insights
    
    def _generate_decision_insights(self, patterns: Dict[str, Any]) -> List[SynthesizedInsight]:
        """Generate insights about decision-making patterns"""
        insights = []
        
        decision_patterns = patterns.get("decision_patterns", {})
        decision_styles = decision_patterns.get("decision_making_styles", {})
        
        # Find most effective decision-making style
        if decision_styles:
            best_style = max(decision_styles.items(), 
                           key=lambda x: x[1].get("effectiveness_indicator", 0))
            
            style_name, style_data = best_style
            effectiveness = style_data.get("effectiveness_indicator", 0)
            
            if effectiveness > 0.7:  # High effectiveness threshold
                insight = SynthesizedInsight(
                    insight_id=str(uuid.uuid4()),
                    insight_type=InsightType.DECISION_IMPACT,
                    priority=InsightPriority.MEDIUM,
                    title=f"'{style_name.title()}' Decision-Making Style Shows High Effectiveness",
                    description=f"Team members using {style_name} decision-making approach show effectiveness score of {effectiveness:.1f}.",
                    supporting_evidence=[
                        f"Effectiveness indicator: {effectiveness:.2f}",
                        f"Average confidence: {style_data.get('average_confidence', 0):.2f}",
                        f"Average stress during decisions: {style_data.get('average_stress_during_decisions', 0):.2f}",
                        f"Frequency: {style_data.get('frequency', 0)} instances"
                    ],
                    affected_projects=list(self.impact_projects.keys()),
                    affected_team_members=[],
                    psychological_factors={
                        "decision_style_effectiveness": style_data,
                        "optimal_style": style_name
                    },
                    confidence_score=min(effectiveness, 0.9),
                    actionable_recommendations=[
                        f"Encourage adoption of {style_name} decision-making approach",
                        "Provide training on effective decision-making strategies",
                        "Document and share best practices from high-effectiveness decisions"
                    ],
                    predicted_impact={
                        "decision_quality": "improved",
                        "team_confidence": "increased",
                        "implementation_success": "higher"
                    }
                )
                insights.append(insight)
        
        return insights
    
    def _generate_trend_insights(self, patterns: Dict[str, Any]) -> List[SynthesizedInsight]:
        """Generate trend prediction insights"""
        insights = []
        
        evolution_patterns = patterns.get("team_evolution_patterns", {})
        collaboration_evolution = evolution_patterns.get("collaboration_evolution", {})
        
        if collaboration_evolution:
            overall_trend = collaboration_evolution.get("overall_trend", "stable")
            engagement_change = collaboration_evolution.get("engagement_change", 0)
            stress_change = collaboration_evolution.get("stress_change", 0)
            
            if overall_trend == "improving":
                insight = SynthesizedInsight(
                    insight_id=str(uuid.uuid4()),
                    insight_type=InsightType.TREND_PREDICTION,
                    priority=InsightPriority.HIGH,
                    title="Positive Team Evolution Trend Detected",
                    description=f"Team collaboration is improving with engagement increasing by {engagement_change:.2f} and stress decreasing by {abs(stress_change):.2f}.",
                    supporting_evidence=[
                        f"Engagement change: +{engagement_change:.2f}",
                        f"Stress change: {stress_change:.2f}",
                        f"Quality improvement: +{collaboration_evolution.get('quality_change', 0):.2f}",
                        f"Overall trend: {overall_trend}"
                    ],
                    affected_projects=list(self.impact_projects.keys()),
                    affected_team_members=[],
                    psychological_factors={
                        "evolution_metrics": collaboration_evolution,
                        "trend_direction": "positive"
                    },
                    confidence_score=0.8,
                    actionable_recommendations=[
                        "Continue current team development strategies",
                        "Document successful practices for replication",
                        "Consider expanding successful approaches to other areas"
                    ],
                    predicted_impact={
                        "team_performance": "continued_improvement",
                        "project_success": "higher",
                        "team_satisfaction": "increased"
                    }
                )
                insights.append(insight)
        
        return insights
    
    def build_knowledge_graph(self, insights: List[SynthesizedInsight]) -> Dict[str, KnowledgeNode]:
        """Build knowledge graph from synthesized insights"""
        print("üï∏Ô∏è Building organizational knowledge graph...")
        
        # Create nodes for insights
        for insight in insights:
            node = KnowledgeNode(
                node_id=insight.insight_id,
                node_type="insight",
                title=insight.title,
                description=insight.description,
                attributes={
                    "insight_type": insight.insight_type.value,
                    "priority": insight.priority.value,
                    "confidence_score": insight.confidence_score,
                    "affected_projects": insight.affected_projects,
                    "psychological_factors": insight.psychological_factors
                }
            )
            self.knowledge_graph[node.node_id] = node
        
        # Create nodes for projects
        for project_id, project_info in self.impact_projects.items():
            node = KnowledgeNode(
                node_id=project_id,
                node_type="project",
                title=project_info["name"],
                description=f"Impact Launchpad project produced by {project_info['producer']}",
                attributes={
                    "producer": project_info["producer"],
                    "focus_areas": project_info["focus_areas"],
                    "sub_projects": project_info.get("sub_projects", [])
                }
            )
            self.knowledge_graph[node.node_id] = node
        
        # Create connections between insights and projects
        self._create_knowledge_connections()
        
        print(f"‚úÖ Knowledge graph built: {len(self.knowledge_graph)} nodes")
        return self.knowledge_graph
    
    def _create_knowledge_connections(self):
        """Create connections between knowledge graph nodes"""
        # Connect insights to projects
        for insight_id, insight_node in self.knowledge_graph.items():
            if insight_node.node_type == "insight":
                affected_projects = insight_node.attributes.get("affected_projects", [])
                
                for project_id in affected_projects:
                    if project_id in self.knowledge_graph:
                        # Add bidirectional connection
                        if project_id not in insight_node.connections:
                            insight_node.connections.append(project_id)
                            insight_node.strength_scores[project_id] = insight_node.attributes.get("confidence_score", 0.5)
                        
                        project_node = self.knowledge_graph[project_id]
                        if insight_id not in project_node.connections:
                            project_node.connections.append(insight_id)
                            project_node.strength_scores[insight_id] = insight_node.attributes.get("confidence_score", 0.5)
        
        # Connect related insights
        insight_nodes = [node for node in self.knowledge_graph.values() if node.node_type == "insight"]
        
        for i, insight1 in enumerate(insight_nodes):
            for insight2 in insight_nodes[i+1:]:
                # Calculate similarity based on affected projects and psychological factors
                similarity = self._calculate_insight_similarity(insight1, insight2)
                
                if similarity > self.knowledge_connection_threshold:
                    insight1.connections.append(insight2.node_id)
                    insight1.strength_scores[insight2.node_id] = similarity
                    
                    insight2.connections.append(insight1.node_id)
                    insight2.strength_scores[insight1.node_id] = similarity
    
    def _calculate_insight_similarity(self, insight1: KnowledgeNode, insight2: KnowledgeNode) -> float:
        """Calculate similarity between two insights"""
        # Project overlap
        projects1 = set(insight1.attributes.get("affected_projects", []))
        projects2 = set(insight2.attributes.get("affected_projects", []))
        
        project_overlap = len(projects1.intersection(projects2)) / max(len(projects1.union(projects2)), 1)
        
        # Insight type similarity
        type1 = insight1.attributes.get("insight_type", "")
        type2 = insight2.attributes.get("insight_type", "")
        type_similarity = 1.0 if type1 == type2 else 0.3
        
        # Combine similarities
        overall_similarity = (project_overlap * 0.6) + (type_similarity * 0.4)
        
        return overall_similarity
    
    def generate_project_intelligence(self) -> Dict[str, ProjectIntelligence]:
        """Generate comprehensive intelligence for each Impact Launchpad project"""
        print("üéØ Generating project-specific intelligence...")
        
        for project_id, project_info in self.impact_projects.items():
            # Get project-related insights
            project_insights = [
                insight for insight in self.synthesized_insights.values()
                if project_id in insight.affected_projects
            ]
            
            # Calculate team engagement for this project
            team_engagement = self._calculate_project_team_engagement(project_id)
            
            # Analyze psychological alignment
            psychological_alignment = self._analyze_project_psychological_alignment(project_id)
            
            # Generate success indicators and risk factors
            success_indicators = self._identify_project_success_indicators(project_id, project_insights)
            risk_factors = self._identify_project_risk_factors(project_id, project_insights)
            
            # Generate optimization opportunities
            optimization_opportunities = self._identify_optimization_opportunities(project_id, project_insights)
            
            # Predict outcomes
            predicted_outcomes = self._predict_project_outcomes(project_id, project_insights, team_engagement)
            
            # Create project intelligence
            intelligence = ProjectIntelligence(
                project_name=project_info["name"],
                project_producer=project_info["producer"],
                key_insights=project_insights,
                team_engagement=team_engagement,
                psychological_alignment=psychological_alignment,
                success_indicators=success_indicators,
                risk_factors=risk_factors,
                optimization_opportunities=optimization_opportunities,
                predicted_outcomes=predicted_outcomes
            )
            
            self.project_intelligence[project_id] = intelligence
        
        print(f"‚úÖ Generated intelligence for {len(self.project_intelligence)} projects")
        return self.project_intelligence
    
    def _calculate_project_team_engagement(self, project_id: str) -> Dict[str, float]:
        """Calculate team engagement levels for a specific project"""
        engagement = {}
        
        # This would analyze debrief responses for project-specific engagement
        # For now, returning placeholder data
        for member_id, member in self.mem0_manager.team_members.items():
            # Base engagement on role and project alignment
            base_engagement = 0.5
            
            # Producer gets higher base engagement
            if member_id == self.impact_projects[project_id]["producer"]:
                base_engagement = 0.9
            
            # Add some variation based on expertise alignment
            project_focus = self.impact_projects[project_id]["focus_areas"]
            member_expertise = member.expertise_areas
            
            overlap = len(set(project_focus).intersection(set(member_expertise)))
            if overlap > 0:
                base_engagement += 0.2 * overlap
            
            engagement[member.name] = min(base_engagement, 1.0)
        
        return engagement
    
    def _analyze_project_psychological_alignment(self, project_id: str) -> Dict[str, Any]:
        """Analyze psychological alignment between team and project"""
        project_info = self.impact_projects[project_id]
        
        # Analyze which psychological types are most aligned with project focus
        alignment = {
            "optimal_mbti_types": [],
            "optimal_disc_types": [],
            "psychological_requirements": {},
            "team_fit_score": 0.0
        }
        
        # Map project focus to psychological preferences
        focus_areas = project_info["focus_areas"]
        
        if "innovation" in focus_areas or "creative" in str(focus_areas):
            alignment["optimal_mbti_types"].extend(["ENTP", "ENFP", "INTP", "INFP"])
            alignment["optimal_disc_types"].append("I")
        
        if "systematic" in str(focus_areas) or "efficiency" in str(focus_areas):
            alignment["optimal_mbti_types"].extend(["INTJ", "ISTJ", "ENTJ", "ESTJ"])
            alignment["optimal_disc_types"].append("C")
        
        if "environmental" in str(focus_areas) or "sustainability" in str(focus_areas):
            alignment["optimal_mbti_types"].extend(["INFP", "ENFP", "INFJ", "ENFJ"])
            alignment["optimal_disc_types"].extend(["I", "S"])
        
        # Calculate team fit score based on current team psychological profiles
        team_fit_scores = []
        for member_id, member in self.mem0_manager.team_members.items():
            profile = self.enhanced_tanka.get_psychological_profile(member_id)
            if profile:
                fit_score = 0.5  # Base score
                
                if profile.mbti_type.value in alignment["optimal_mbti_types"]:
                    fit_score += 0.3
                
                if profile.disc_primary.value in alignment["optimal_disc_types"]:
                    fit_score += 0.2
                
                team_fit_scores.append(fit_score)
        
        alignment["team_fit_score"] = np.mean(team_fit_scores) if team_fit_scores else 0.5
        
        return alignment
    
    def _identify_project_success_indicators(self, project_id: str, insights: List[SynthesizedInsight]) -> List[str]:
        """Identify success indicators for a project"""
        indicators = []
        
        # Analyze insights for positive indicators
        for insight in insights:
            if insight.priority in [InsightPriority.HIGH, InsightPriority.CRITICAL]:
                if "high" in insight.title.lower() and "interest" in insight.title.lower():
                    indicators.append("Strong cross-team interest and engagement")
                
                if "improving" in insight.description.lower():
                    indicators.append("Positive team evolution trends")
                
                if "effectiveness" in insight.title.lower():
                    indicators.append("Effective decision-making patterns")
        
        # Add project-specific indicators
        project_info = self.impact_projects[project_id]
        if "innovation" in project_info["focus_areas"]:
            indicators.append("High creative engagement from team members")
        
        if "sustainability" in project_info["focus_areas"]:
            indicators.append("Strong environmental consciousness in team discussions")
        
        return indicators
    
    def _identify_project_risk_factors(self, project_id: str, insights: List[SynthesizedInsight]) -> List[str]:
        """Identify risk factors for a project"""
        risks = []
        
        # Analyze insights for risk indicators
        for insight in insights:
            if "stress" in insight.title.lower() and insight.priority == InsightPriority.HIGH:
                risks.append("Elevated stress levels in key team members")
            
            if "declining" in insight.description.lower():
                risks.append("Declining team performance trends")
        
        # Add project-specific risks
        project_info = self.impact_projects[project_id]
        producer_id = project_info["producer"]
        
        # Check if producer is showing stress
        # This would require actual debrief data analysis
        risks.append("Dependency on single producer for project leadership")
        
        return risks
    
    def _identify_optimization_opportunities(self, project_id: str, insights: List[SynthesizedInsight]) -> List[str]:
        """Identify optimization opportunities for a project"""
        opportunities = []
        
        # Analyze insights for optimization potential
        for insight in insights:
            if "cross-team" in insight.title.lower():
                opportunities.append("Leverage cross-team interest for collaborative expansion")
            
            if "effectiveness" in insight.title.lower():
                opportunities.append("Scale effective practices to other project areas")
        
        # Add general optimization opportunities
        opportunities.extend([
            "Implement psychological profile-based task allocation",
            "Optimize meeting frequency and format based on team preferences",
            "Develop project-specific stress management strategies"
        ])
        
        return opportunities
    
    def _predict_project_outcomes(self, project_id: str, insights: List[SynthesizedInsight], team_engagement: Dict[str, float]) -> Dict[str, Any]:
        """Predict project outcomes based on current patterns"""
        outcomes = {
            "success_probability": 0.7,  # Base probability
            "timeline_prediction": "on_track",
            "team_satisfaction_prediction": "high",
            "innovation_potential": "medium",
            "sustainability_score": 0.6
        }
        
        # Adjust based on insights
        positive_insights = len([i for i in insights if "improving" in i.description.lower() or "high" in i.title.lower()])
        negative_insights = len([i for i in insights if "stress" in i.title.lower() or "declining" in i.description.lower()])
        
        # Adjust success probability
        outcomes["success_probability"] += (positive_insights * 0.1) - (negative_insights * 0.15)
        outcomes["success_probability"] = max(0.1, min(0.95, outcomes["success_probability"]))
        
        # Adjust based on team engagement
        avg_engagement = np.mean(list(team_engagement.values()))
        if avg_engagement > 0.8:
            outcomes["team_satisfaction_prediction"] = "very_high"
            outcomes["innovation_potential"] = "high"
        elif avg_engagement < 0.4:
            outcomes["team_satisfaction_prediction"] = "low"
            outcomes["timeline_prediction"] = "at_risk"
        
        return outcomes
    
    def get_synthesis_summary(self) -> Dict[str, Any]:
        """Get comprehensive summary of insight synthesis"""
        return {
            "total_insights": len(self.synthesized_insights),
            "insights_by_type": {
                insight_type.value: len([i for i in self.synthesized_insights.values() if i.insight_type == insight_type])
                for insight_type in InsightType
            },
            "insights_by_priority": {
                priority.value: len([i for i in self.synthesized_insights.values() if i.priority == priority])
                for priority in InsightPriority
            },
            "knowledge_graph_nodes": len(self.knowledge_graph),
            "project_intelligence_generated": len(self.project_intelligence),
            "average_confidence_score": np.mean([i.confidence_score for i in self.synthesized_insights.values()]) if self.synthesized_insights else 0,
            "last_synthesis": datetime.now().isoformat()
        }

# Example usage and testing
if __name__ == "__main__":
    # Test InsightSynthesizer (requires components from previous phases)
    try:
        # Initialize components
        mem0_manager = Mem0Manager()
        enhanced_tanka = EnhancedTankaProfileLoader(mem0_manager)
        debrief_collector = DebriefCollector(mem0_manager, enhanced_tanka)
        insight_synthesizer = InsightSynthesizer(mem0_manager, enhanced_tanka, debrief_collector)
        
        print("üß† InsightSynthesizer initialized successfully!")
        
        # Test pattern analysis (would need actual debrief data)
        patterns = insight_synthesizer.analyze_collective_patterns(time_window_days=30)
        print(f"üìä Pattern analysis: {patterns.get('status', 'completed')}")
        
        # Test insight generation
        insights = insight_synthesizer.generate_strategic_insights(patterns)
        print(f"üéØ Generated {len(insights)} strategic insights")
        
        # Test knowledge graph building
        knowledge_graph = insight_synthesizer.build_knowledge_graph(insights)
        print(f"üï∏Ô∏è Knowledge graph: {len(knowledge_graph)} nodes")
        
        # Test project intelligence
        project_intelligence = insight_synthesizer.generate_project_intelligence()
        print(f"üìà Project intelligence: {len(project_intelligence)} projects")
        
        # Get synthesis summary
        summary = insight_synthesizer.get_synthesis_summary()
        print(f"üìã Synthesis summary: {summary}")
        
        print("\n‚úÖ InsightSynthesizer successfully tested!")
        
    except Exception as e:
        print(f"‚ùå Error testing InsightSynthesizer: {e}")
        print("üí° This requires components from previous phases to be properly initialized")

